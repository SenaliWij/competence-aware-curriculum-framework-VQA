{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMJkdu/oLN84DKbVvrghSSg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0Ynv7XE6nLtd","executionInfo":{"status":"ok","timestamp":1769865107611,"user_tz":-330,"elapsed":18277,"user":{"displayName":"Senali Wijesekera","userId":"09658199555257314867"}},"outputId":"f757bca1-1ebc-49aa-d2f6-73177f911960"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!cp /content/drive/MyDrive/Colab\\ Notebooks/FYP/data/clevr_dataset_py.py /content\n","!cp /content/drive/MyDrive/Colab\\ Notebooks/FYP/models/vilt_vqa_model_py.py /content\n"],"metadata":{"id":"WBIKWaF9nOEN","executionInfo":{"status":"ok","timestamp":1769866104361,"user_tz":-330,"elapsed":1322,"user":{"displayName":"Senali Wijesekera","userId":"09658199555257314867"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["import os\n","import math\n","import random\n","from dataclasses import dataclass\n","from typing import Dict, List, Optional, Tuple\n","\n","import torch\n","from torch.utils.data import DataLoader\n","from transformers import ViltProcessor, get_linear_schedule_with_warmup\n","\n","# import clevr_dataset_py\n","# import vilt_vqa_model_py\n","\n","from clevr_dataset_py import CLEVRCurriculumViltDataset, vilt_collate_fn, build_answer_vocab\n","from vilt_vqa_model_py import get_clevr_model\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xri8cK3YnWbB","outputId":"8ebc2fe5-a4e8-4926-e8d0-a2f5e6ebc26c","executionInfo":{"status":"ok","timestamp":1769867403606,"user_tz":-330,"elapsed":24025,"user":{"displayName":"Senali Wijesekera","userId":"09658199555257314867"}}},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n"]},{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["# =========================\n","# Configuration (paths + processor)\n","# =========================\n","QUESTIONS_DIR = \"/content/drive/MyDrive/Colab Notebooks/FYP/dataset/clevr_kaggle/CLEVR_v1.0/questions\"\n","IMAGES_DIR    = \"/content/drive/MyDrive/Colab Notebooks/FYP/dataset/clevr_kaggle/CLEVR_v1.0/images\"\n","\n","processor = ViltProcessor.from_pretrained(\"dandelin/vilt-b32-mlm\")\n","\n","# Build answer vocab (from all train tiers)\n","tier_paths = [os.path.join(QUESTIONS_DIR, f\"CLEVR_train_questions_L{i}.json\") for i in [1,2,3,4,5]]\n","answer2id = build_answer_vocab(tier_paths)\n","print(\"Answer vocab size:\", len(answer2id))\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Device:\", device)\n","\n","\n","def data_loader_for_tier(\n","    tier: int,\n","    split: str = \"train\",\n","    batch_size: int = 16,\n","    max_length: int = 32,\n","    shuffle: bool = True,\n",") -> DataLoader:\n","  dataset_sample = CLEVRCurriculumViltDataset(\n","        questions_dir=QUESTIONS_DIR,\n","        images_dir=IMAGES_DIR,\n","        processor=processor,\n","        split=split,\n","        tiers=[tier],\n","        answer2id=answer2id,\n","        max_length=max_length,\n","    )\n","  loader = DataLoader(\n","        dataset_sample,\n","        batch_size=batch_size,\n","        shuffle=shuffle if split == \"train\" else False,\n","        num_workers=0,           # keep 0 on Drive\n","        pin_memory=True,\n","        collate_fn=vilt_collate_fn,\n","    )\n","  return loader\n","\n","\n","# Quick sanity check Tier-1 batch shapes (same as you had)\n","train_loader_L1 = data_loader_for_tier(1, split=\"train\", batch_size=16, shuffle=True)\n","batch = next(iter(train_loader_L1))\n","for k, v in batch.items():\n","    print(k, v.shape, v.dtype)\n"],"metadata":{"id":"dtN3qu68nicy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1769867470780,"user_tz":-330,"elapsed":57387,"user":{"displayName":"Senali Wijesekera","userId":"09658199555257314867"}},"outputId":"0eb24e72-d2b2-4859-d0c3-49bb74c91053"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Answer vocab size: 28\n","Device: cpu\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n","  warnings.warn(warn_msg)\n"]},{"output_type":"stream","name":"stdout","text":["pixel_values torch.Size([16, 3, 384, 576]) torch.float32\n","pixel_mask torch.Size([16, 384, 576]) torch.int64\n","input_ids torch.Size([16, 32]) torch.int64\n","token_type_ids torch.Size([16, 32]) torch.int64\n","attention_mask torch.Size([16, 32]) torch.int64\n","tier torch.Size([16]) torch.int64\n","question_id torch.Size([16]) torch.int64\n","labels torch.Size([16]) torch.int64\n"]}]},{"cell_type":"code","source":["model = get_clevr_model(answer2id=answer2id)\n","model.to(device)\n","\n","optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zzZz7LY7QbPm","executionInfo":{"status":"ok","timestamp":1769867502019,"user_tz":-330,"elapsed":3170,"user":{"displayName":"Senali Wijesekera","userId":"09658199555257314867"}},"outputId":"69bc546c-9e27-4a46-9853-9435d286ced9"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of ViltForQuestionAnswering were not initialized from the model checkpoint at dandelin/vilt-b32-mlm-itm and are newly initialized: ['classifier.0.bias', 'classifier.0.weight', 'classifier.1.bias', 'classifier.1.weight', 'classifier.3.bias', 'classifier.3.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["import torch\n","\n","def train_samples(model, train_loader, optimizer, device, epochs=1, max_batches=50):\n","    model.train()\n","\n","    # Only pass the keys that ViLT expects\n","    ALLOWED_KEYS = {\n","        \"input_ids\",\n","        \"attention_mask\",\n","        \"token_type_ids\",\n","        \"pixel_values\",\n","        \"pixel_mask\",\n","        \"labels\",\n","    }\n","\n","    for epoch in range(epochs):\n","        running_loss = 0.0\n","        steps = 0\n","\n","        for b_idx, batch in enumerate(train_loader):\n","            if max_batches is not None and b_idx >= max_batches:\n","                break\n","\n","            # # 1) keep only model inputs\n","            # batch = {k: v for k, v in batch.items() if k in ALLOWED_KEYS}\n","\n","            # # 2) move tensors to device\n","            # batch = {k: v.to(device) for k, v in batch.items()}\n","\n","            # # 3) forward + loss\n","            # outputs = model(**batch)\n","            # loss = outputs.loss\n","              # keep only model inputs\n","            batch = {k: v for k, v in batch.items() if k in ALLOWED_KEYS}\n","\n","            # convert labels -> multi-hot\n","            labels = batch[\"labels\"]                # [B]\n","            num_labels = model.config.num_labels\n","\n","            multi_hot = torch.zeros(\n","                labels.size(0), num_labels, device=labels.device\n","            )\n","            multi_hot.scatter_(1, labels.unsqueeze(1), 1.0)\n","\n","            batch[\"labels\"] = multi_hot             # [B, num_labels]\n","\n","            # move to device\n","            batch = {k: v.to(device) for k, v in batch.items()}\n","\n","            outputs = model(**batch)\n","            loss = outputs.loss\n","\n","\n","            optimizer.zero_grad(set_to_none=True)\n","            loss.backward()\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","            optimizer.step()\n","\n","            running_loss += loss.item()\n","            steps += 1\n","\n","            if (b_idx + 1) % 10 == 0:\n","                print(f\"Epoch {epoch+1} | Batch {b_idx+1} | Loss: {loss.item():.4f}\")\n","\n","        print(f\"âœ… Epoch {epoch+1} finished | Avg loss: {running_loss / max(steps, 1):.4f}\")\n"],"metadata":{"id":"o6oBYTl4Q40q","executionInfo":{"status":"ok","timestamp":1769867508440,"user_tz":-330,"elapsed":45,"user":{"displayName":"Senali Wijesekera","userId":"09658199555257314867"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["\n","train_samples(model, train_loader_L1, optimizer, device, epochs=1, max_batches=50)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A3gY2JItQ7Lt","executionInfo":{"status":"ok","timestamp":1769869924299,"user_tz":-330,"elapsed":2411409,"user":{"displayName":"Senali Wijesekera","userId":"09658199555257314867"}},"outputId":"70830256-2731-4708-b282-6c549433be0c"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1 | Batch 10 | Loss: 12.5392\n","Epoch 1 | Batch 20 | Loss: 7.1218\n","Epoch 1 | Batch 30 | Loss: 4.8211\n","Epoch 1 | Batch 40 | Loss: 4.1678\n","Epoch 1 | Batch 50 | Loss: 3.5618\n","âœ… Epoch 1 finished | Avg loss: 7.7943\n"]}]},{"cell_type":"code","source":["SAVE_DIR = \"/content/drive/MyDrive/Colab Notebooks/FYP/checkpoints/vilt_L1_from_memory\"\n","\n","import os\n","os.makedirs(SAVE_DIR, exist_ok=True)\n","\n","model.save_pretrained(SAVE_DIR)\n","processor.save_pretrained(SAVE_DIR)\n","\n","print(\"âœ… Model exported from memory to:\", SAVE_DIR)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iDst8ICyRW_I","executionInfo":{"status":"ok","timestamp":1769870774542,"user_tz":-330,"elapsed":7526,"user":{"displayName":"Senali Wijesekera","userId":"09658199555257314867"}},"outputId":"11bd3efb-6546-4821-a9b9-071e9da43dbe"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… Model exported from memory to: /content/drive/MyDrive/Colab Notebooks/FYP/checkpoints/vilt_L1_from_memory\n"]}]},{"cell_type":"code","source":["import torch\n","from transformers import ViltForQuestionAnswering, ViltProcessor\n","\n","SAVE_DIR = \"/content/drive/MyDrive/Colab Notebooks/FYP/checkpoints/vilt_L1_from_memory\"\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Reload model + processor\n","model = ViltForQuestionAnswering.from_pretrained(SAVE_DIR).to(device)\n","processor = ViltProcessor.from_pretrained(SAVE_DIR)\n","\n","# id2answer\n","id2answer = {i: a for a, i in answer2id.items()}\n","\n","# âœ… Get ONE sample from the DATASET (inside the DataLoader)\n","ds = train_loader_L1.dataset\n","sample = ds[3]   # now this works\n","\n","print(\"Sample keys:\", list(sample.keys()))\n","\n","# Keep only model inputs\n","KEEP = {\"input_ids\", \"attention_mask\", \"token_type_ids\", \"pixel_values\", \"pixel_mask\"}\n","sample_inputs = {k: v for k, v in sample.items() if k in KEEP}\n","\n","# Add batch dimension + move to device\n","sample_inputs = {k: v.unsqueeze(0).to(device) for k, v in sample_inputs.items()}\n","\n","# Inference\n","model.eval()\n","with torch.no_grad():\n","    logits = model(**sample_inputs).logits\n","    pred_id = int(logits.argmax(dim=-1).item())\n","\n","print(\"âœ… Predicted answer:\", id2answer[pred_id])\n","\n","# Optional: compare with ground truth (if your sample includes labels)\n","if \"labels\" in sample:\n","    true_id = int(sample[\"labels\"])\n","    print(\"ðŸŽ¯ True answer:\", id2answer[true_id])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_bKn6hcihLKE","executionInfo":{"status":"ok","timestamp":1769871653005,"user_tz":-330,"elapsed":2515,"user":{"displayName":"Senali Wijesekera","userId":"09658199555257314867"}},"outputId":"377a1f6f-0a3e-4988-b96a-f6641790c373"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Sample keys: ['pixel_values', 'pixel_mask', 'input_ids', 'token_type_ids', 'attention_mask', 'labels', 'tier', 'question_id']\n","âœ… Predicted answer: yes\n","ðŸŽ¯ True answer: cube\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"9MZIRITQicUl"},"execution_count":null,"outputs":[]}]}