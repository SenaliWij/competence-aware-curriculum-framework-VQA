{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1052e3b-2034-4c5b-9f46-8d7d378a0b76",
      "metadata": {
        "scrolled": true,
        "id": "a1052e3b-2034-4c5b-9f46-8d7d378a0b76"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get number of questions in original dataset\n"
      ],
      "metadata": {
        "id": "dAdTw1QiBOiK"
      },
      "id": "dAdTw1QiBOiK"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7df4aa3f-9946-4077-87cc-7364c474b1e6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7df4aa3f-9946-4077-87cc-7364c474b1e6",
        "outputId": "783e525f-4521-4cd4-915c-13bc5b7850a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L1: 41884 questions\n",
            "L2: 6780 questions\n",
            "L3: 26981 questions\n",
            "L4: 32046 questions\n",
            "L5: 42300 questions\n",
            "149991\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "base_path = r\"/content/drive/MyDrive/Colab Notebooks/FYP/dataset/clevr_kaggle/CLEVR_v1.0/questions\"\n",
        "total_q = 0\n",
        "\n",
        "for i in range(1, 6):\n",
        "    json_path = rf\"{base_path}/CLEVR_val_questions_L{i}.json\"\n",
        "\n",
        "    try:\n",
        "        with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "        num_questions = len(data[\"questions\"])\n",
        "        print(f\"L{i}: {num_questions} questions\")\n",
        "        total_q += num_questions\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"L{i}: File not found â†’ {json_path}\")\n",
        "\n",
        "    except KeyError:\n",
        "        print(f\"L{i}: Missing 'questions' key in file\")\n",
        "\n",
        "print(total_q)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54c80061-00de-4bba-a775-43157e4c7822",
      "metadata": {
        "id": "54c80061-00de-4bba-a775-43157e4c7822"
      },
      "source": [
        "## Downsampling with skewness and from the train dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "361a13b2-4d9e-47df-9bdb-2af370017031",
      "metadata": {
        "id": "361a13b2-4d9e-47df-9bdb-2af370017031"
      },
      "source": [
        "avg = 2.87  â†’ on average, each image appears in ~3 questions\n",
        "max = 9     â†’ worst case: one image appears 9 times"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84d4dafe-0d37-4955-982f-e89d2f11fd79",
      "metadata": {
        "id": "84d4dafe-0d37-4955-982f-e89d2f11fd79",
        "outputId": "223945c1-e237-4f1a-edfe-58e1143d4831"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "L1: avg=2.87, max=9\n",
            "L2: avg=1.16, max=3\n",
            "L3: avg=2.00, max=8\n",
            "L4: avg=2.30, max=7\n",
            "L5: avg=2.87, max=8\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from collections import Counter\n",
        "\n",
        "path = r\"D:\\VS Projects\\seli-fyp\\competence-aware-curriculum-framework-VQA\\dataset\\CLEVR_v1.0\\questions\"\n",
        "\n",
        "for i in range(1,6):\n",
        "    with open(rf\"{path}\\CLEVR_train_questions_L{i}.json\") as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    counts = Counter(q[\"image_index\"] for q in data[\"questions\"])\n",
        "\n",
        "    avg = sum(counts.values()) / len(counts)\n",
        "    mx = max(counts.values())\n",
        "\n",
        "    print(f\"L{i}: avg={avg:.2f}, max={mx}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CLEVR Curriculum Tier Dataset Statistics Analyzer**"
      ],
      "metadata": {
        "id": "s4WKpWGWBtu-"
      },
      "id": "s4WKpWGWBtu-"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Option A : Computes downsampled dataset stats"
      ],
      "metadata": {
        "id": "zQVxPgbjCcK6"
      },
      "id": "zQVxPgbjCcK6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e15bcaf-e152-4301-9042-249afca5ffa9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6e15bcaf-e152-4301-9042-249afca5ffa9",
        "outputId": "9e4d5ec3-51b3-4718-84a9-c6f5a15fe1ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Š CLEVR TRAIN BALANCED DATASET STATS\n",
            "\n",
            "Files found: ['CLEVR_train_questions_L1.json', 'CLEVR_train_questions_L2.json', 'CLEVR_train_questions_L3.json', 'CLEVR_train_questions_L4.json', 'CLEVR_train_questions_L5.json'] \n",
            "\n",
            "=== CLEVR_train_questions_L1.json ===\n",
            "Tier                  : L1\n",
            "Total questions       : 60000\n",
            "Unique images         : 31929\n",
            "Avg questions / image : 1.88\n",
            "Max questions / image : 2\n",
            "\n",
            "=== CLEVR_train_questions_L2.json ===\n",
            "Tier                  : L2\n",
            "Total questions       : 31437\n",
            "Unique images         : 27208\n",
            "Avg questions / image : 1.16\n",
            "Max questions / image : 3\n",
            "\n",
            "=== CLEVR_train_questions_L3.json ===\n",
            "Tier                  : L3\n",
            "Total questions       : 60000\n",
            "Unique images         : 36563\n",
            "Avg questions / image : 1.64\n",
            "Max questions / image : 2\n",
            "\n",
            "=== CLEVR_train_questions_L4.json ===\n",
            "Tier                  : L4\n",
            "Total questions       : 60000\n",
            "Unique images         : 34307\n",
            "Avg questions / image : 1.75\n",
            "Max questions / image : 2\n",
            "\n",
            "=== CLEVR_train_questions_L5.json ===\n",
            "Tier                  : L5\n",
            "Total questions       : 70000\n",
            "Unique images         : 28317\n",
            "Avg questions / image : 2.47\n",
            "Max questions / image : 3\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "from collections import Counter\n",
        "\n",
        "# Base directory containing downsampled CLEVR tier JSON files\n",
        "# Updated for Google Colab + Google Drive environment\n",
        "BASE_DIR = \"/content/drive/MyDrive/Colab Notebooks/FYP/CLEVR/downsampled\"\n",
        "\n",
        "\n",
        "def analyze_tier(json_path):\n",
        "    \"\"\"\n",
        "    Analyze a single CLEVR tier JSON file and compute dataset statistics and returns:\n",
        "    total_q : int\n",
        "        Total number of questions in the tier.\n",
        "    num_images : int\n",
        "        Number of unique images referenced in the tier.\n",
        "    avg_q_per_img : float\n",
        "        Average number of questions per image.\n",
        "    max_q_per_img : int\n",
        "        Maximum number of questions associated with a single image.\n",
        "    \"\"\"\n",
        "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    # Extract questions list following CLEVR JSON structure\n",
        "    questions = data.get(\"questions\", [])\n",
        "    total_q = len(questions)\n",
        "\n",
        "    # Count how many times each image is referenced\n",
        "    image_counter = Counter(\n",
        "        q[\"image_filename\"] for q in questions\n",
        "    )\n",
        "\n",
        "    num_images = len(image_counter)\n",
        "    avg_q_per_img = total_q / num_images if num_images else 0\n",
        "    max_q_per_img = max(image_counter.values()) if num_images else 0\n",
        "\n",
        "    return total_q, num_images, avg_q_per_img, max_q_per_img\n",
        "\n",
        "print(\"CLEVR TRAIN BALANCED DATASET STATISTICS\")\n",
        "\n",
        "# Sanity check to ensure expected files exist in the directory\n",
        "print(\"Files found:\", os.listdir(BASE_DIR), \"\\n\")\n",
        "\n",
        "# Iterate through all tier JSON files and report statistics\n",
        "for file in sorted(os.listdir(BASE_DIR)):\n",
        "    if not file.lower().endswith(\".json\"):\n",
        "        continue\n",
        "\n",
        "    # Identify tier level from filename\n",
        "    tier = None\n",
        "    for t in [\"L1\", \"L2\", \"L3\", \"L4\", \"L5\"]:\n",
        "        if t in file:\n",
        "            tier = t\n",
        "            break\n",
        "\n",
        "    if tier is None:\n",
        "        continue\n",
        "\n",
        "    path = os.path.join(BASE_DIR, file)\n",
        "    total_q, num_images, avg_q, max_q = analyze_tier(path)\n",
        "\n",
        "    print(f\"=== {file} ===\")\n",
        "    print(f\"Tier                  : {tier}\")\n",
        "    print(f\"Total questions       : {total_q}\")\n",
        "    print(f\"Unique images         : {num_images}\")\n",
        "    print(f\"Avg questions / image : {avg_q:.2f}\")\n",
        "    print(f\"Max questions / image : {max_q}\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Option B : Computes downsampled dataset stats"
      ],
      "metadata": {
        "id": "Zwop8tULSqyB"
      },
      "id": "Zwop8tULSqyB"
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "from collections import Counter\n",
        "\n",
        "# ðŸ”§ UPDATED PATH FOR COLAB\n",
        "BASE_DIR = \"/content/drive/MyDrive/Colab Notebooks/FYP/CLEVR/downsampledV2\"\n",
        "\n",
        "def analyze_tier(json_path):\n",
        "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    # CLEVR format\n",
        "    questions = data.get(\"questions\", [])\n",
        "    total_q = len(questions)\n",
        "\n",
        "    image_counter = Counter(\n",
        "        q[\"image_filename\"] for q in questions\n",
        "    )\n",
        "\n",
        "    num_images = len(image_counter)\n",
        "    avg_q_per_img = total_q / num_images if num_images else 0\n",
        "    max_q_per_img = max(image_counter.values()) if num_images else 0\n",
        "\n",
        "    return total_q, num_images, avg_q_per_img, max_q_per_img\n",
        "\n",
        "\n",
        "print(\"\\nðŸ“Š CLEVR TRAIN BALANCED DATASET STATS\\n\")\n",
        "\n",
        "# Optional: sanity check\n",
        "print(\"Files found:\", os.listdir(BASE_DIR), \"\\n\")\n",
        "\n",
        "for file in sorted(os.listdir(BASE_DIR)):\n",
        "    if not file.lower().endswith(\".json\"):\n",
        "        continue\n",
        "\n",
        "    tier = None\n",
        "    for t in [\"L1\", \"L2\", \"L3\", \"L4\", \"L5\"]:\n",
        "        if t in file:\n",
        "            tier = t\n",
        "            break\n",
        "\n",
        "    if tier is None:\n",
        "        continue\n",
        "\n",
        "    path = os.path.join(BASE_DIR, file)\n",
        "    total_q, num_images, avg_q, max_q = analyze_tier(path)\n",
        "\n",
        "    print(f\"=== {file} ===\")\n",
        "    print(f\"Tier                  : {tier}\")\n",
        "    print(f\"Total questions       : {total_q}\")\n",
        "    print(f\"Unique images         : {num_images}\")\n",
        "    print(f\"Avg questions / image : {avg_q:.2f}\")\n",
        "    print(f\"Max questions / image : {max_q}\")\n",
        "    print()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwLdW-lex6rj",
        "outputId": "f4c8e334-c55a-412b-ffac-214805a19620"
      },
      "id": "qwLdW-lex6rj",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Š CLEVR TRAIN BALANCED DATASET STATS\n",
            "\n",
            "Files found: ['CLEVR_train_questions_L1.json', 'CLEVR_train_questions_L2.json', 'CLEVR_train_questions_L3.json', 'CLEVR_train_questions_L4.json', 'CLEVR_train_questions_L5.json'] \n",
            "\n",
            "=== CLEVR_train_questions_L1.json ===\n",
            "Tier                  : L1\n",
            "Total questions       : 60000\n",
            "Unique images         : 60000\n",
            "Avg questions / image : 1.00\n",
            "Max questions / image : 1\n",
            "\n",
            "=== CLEVR_train_questions_L2.json ===\n",
            "Tier                  : L2\n",
            "Total questions       : 31437\n",
            "Unique images         : 27208\n",
            "Avg questions / image : 1.16\n",
            "Max questions / image : 3\n",
            "\n",
            "=== CLEVR_train_questions_L3.json ===\n",
            "Tier                  : L3\n",
            "Total questions       : 60000\n",
            "Unique images         : 60000\n",
            "Avg questions / image : 1.00\n",
            "Max questions / image : 1\n",
            "\n",
            "=== CLEVR_train_questions_L4.json ===\n",
            "Tier                  : L4\n",
            "Total questions       : 60000\n",
            "Unique images         : 60000\n",
            "Avg questions / image : 1.00\n",
            "Max questions / image : 1\n",
            "\n",
            "=== CLEVR_train_questions_L5.json ===\n",
            "Tier                  : L5\n",
            "Total questions       : 70000\n",
            "Unique images         : 68488\n",
            "Avg questions / image : 1.02\n",
            "Max questions / image : 2\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TRANING DOWNSAMPLE**"
      ],
      "metadata": {
        "id": "sj7V6UxaSz4S"
      },
      "id": "sj7V6UxaSz4S"
    },
    {
      "cell_type": "markdown",
      "source": [
        "DOWNSAMPLE OPTION A\n",
        "\n",
        "* Downsampling questions per image to avoid image bias\n",
        "* Enforcing tier-specific question caps\n",
        "* Preserving reasoning diversity while controlling dataset size\n",
        "\n",
        "Flow\n",
        "\n",
        "1. Group questions by image\n",
        "2. Randomly shuffle images and questions (seeded for reproducibility)\n",
        "3. Select a limited number of questions per image\n",
        "4. Stop once the tierâ€™s target size is reached\n"
      ],
      "metadata": {
        "id": "eXGHNn_XKvXX"
      },
      "id": "eXGHNn_XKvXX"
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import random\n",
        "import os\n",
        "from collections import defaultdict\n",
        "from google.colab import drive\n",
        "\n",
        "# -------- MOUNT GOOGLE DRIVE -------- #\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ---------------- CONFIG ---------------- #\n",
        "INPUT_DIR = \"/content/drive/MyDrive/Colab Notebooks/FYP/dataset/clevr_kaggle/CLEVR_v1.0/questions\"\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/Colab Notebooks/FYP/CLEVR/downsampledV3\"\n",
        "\n",
        "MAX_Q_PER_IMAGE = {\n",
        "    1: 2,  # primary cap for L1\n",
        "    2: 1,  # ignored (we keep all)\n",
        "    3: 2,\n",
        "    4: 2,\n",
        "    5: 3,\n",
        "}\n",
        "\n",
        "TARGET_PER_TIER = {\n",
        "    1: 60000,\n",
        "    2: None,   # keep all\n",
        "    3: 60000,\n",
        "    4: 60000,\n",
        "    5: 70000,\n",
        "}\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "# ---------------------------------------- #\n",
        "\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "def downsample_tier(tier):\n",
        "    input_file = os.path.join(INPUT_DIR, f\"CLEVR_train_questions_L{tier}.json\")\n",
        "    output_file = os.path.join(OUTPUT_DIR, f\"CLEVR_train_questions_L{tier}.json\")\n",
        "\n",
        "    with open(input_file, \"r\") as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    questions = data[\"questions\"]\n",
        "\n",
        "    # ---------- TIER 2: KEEP ALL ----------\n",
        "    if tier == 2:\n",
        "        out_data = {\n",
        "            \"info\": data.get(\"info\", {}),\n",
        "            \"questions\": questions\n",
        "        }\n",
        "        with open(output_file, \"w\") as f:\n",
        "            json.dump(out_data, f)\n",
        "\n",
        "        print(f\"âœ… Tier L2: kept ALL {len(questions)} questions â†’ {output_file}\")\n",
        "        return\n",
        "\n",
        "    # ---------- OTHER TIERS ----------\n",
        "    image_map = defaultdict(list)\n",
        "    for q in questions:\n",
        "        image_map[q[\"image_index\"]].append(q)\n",
        "\n",
        "    image_ids = list(image_map.keys())\n",
        "    random.shuffle(image_ids)\n",
        "\n",
        "    collected = []\n",
        "    target = TARGET_PER_TIER[tier]\n",
        "    primary_cap = MAX_Q_PER_IMAGE[tier]\n",
        "\n",
        "    # ----- PASS 1: primary cap -----\n",
        "    leftovers = defaultdict(list)\n",
        "\n",
        "    for img_id in image_ids:\n",
        "        qs = image_map[img_id]\n",
        "        random.shuffle(qs)\n",
        "\n",
        "        collected.extend(qs[:primary_cap])\n",
        "        leftovers[img_id] = qs[primary_cap:]\n",
        "\n",
        "        if target and len(collected) >= target:\n",
        "            collected = collected[:target]\n",
        "            break\n",
        "\n",
        "    random.shuffle(collected)\n",
        "\n",
        "    out_data = {\n",
        "        \"info\": data.get(\"info\", {}),\n",
        "        \"questions\": collected\n",
        "    }\n",
        "\n",
        "    with open(output_file, \"w\") as f:\n",
        "        json.dump(out_data, f)\n",
        "\n",
        "    print(\n",
        "        f\"âœ… Tier L{tier}: kept={len(collected)} \"\n",
        "        f\"(primary={primary_cap}\"\n",
        "        f\"{', +2 fill' if tier == 1 else ''}) â†’ {output_file}\"\n",
        "    )\n",
        "\n",
        "\n",
        "# -------- RUN FOR ALL TIERS -------- #\n",
        "for tier in [1, 2, 3, 4, 5]:\n",
        "    downsample_tier(tier)\n",
        "\n",
        "print(\"\\nðŸŽ¯ All tiers downsampled successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZ26tI1_eIJ5",
        "outputId": "cc764fef-6d81-40cd-c675-321b6b2c80c4"
      },
      "id": "hZ26tI1_eIJ5",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "âœ… Tier L1: kept=60000 (primary=2, +2 fill) â†’ /content/drive/MyDrive/Colab Notebooks/FYP/CLEVR/downsampled/CLEVR_train_questions_L1.json\n",
            "âœ… Tier L2: kept ALL 31437 questions â†’ /content/drive/MyDrive/Colab Notebooks/FYP/CLEVR/downsampled/CLEVR_train_questions_L2.json\n",
            "âœ… Tier L3: kept=60000 (primary=2) â†’ /content/drive/MyDrive/Colab Notebooks/FYP/CLEVR/downsampled/CLEVR_train_questions_L3.json\n",
            "âœ… Tier L4: kept=60000 (primary=2) â†’ /content/drive/MyDrive/Colab Notebooks/FYP/CLEVR/downsampled/CLEVR_train_questions_L4.json\n",
            "âœ… Tier L5: kept=70000 (primary=3) â†’ /content/drive/MyDrive/Colab Notebooks/FYP/CLEVR/downsampled/CLEVR_train_questions_L5.json\n",
            "\n",
            "ðŸŽ¯ All tiers downsampled successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DOWNSAMPLE OPTION B - ROUND ROBIN BASIS\n",
        "\n",
        "* Explicitly controlling the average number of questions per image  \n",
        "* Enforcing uniform image coverage via round-robin sampling\n",
        "* Preserving CLEVRâ€™s compositional reasoning structure\n",
        "\n",
        "Flow\n",
        "\n",
        "\n",
        "\n",
        "1. Take 1 question from every image\n",
        "2. Continue until: Target size is reached, or Image question limit is reached"
      ],
      "metadata": {
        "id": "qxIZqJG_-vOc"
      },
      "id": "qxIZqJG_-vOc"
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import random\n",
        "import os\n",
        "from collections import defaultdict\n",
        "from google.colab import drive\n",
        "import math\n",
        "\n",
        "# -------- MOUNT GOOGLE DRIVE -------- #\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ---------------- CONFIG ---------------- #\n",
        "INPUT_DIR = \"/content\"\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/Colab Notebooks/FYP/CLEVR/downsampledV2\"\n",
        "\n",
        "TARGET_AVG_Q_PER_IMAGE = {\n",
        "    1: 3.0,\n",
        "    2: 1.16,\n",
        "    3: 2.0,\n",
        "    4: 2.3,\n",
        "    5: 3.0,\n",
        "}\n",
        "\n",
        "TARGET_PER_TIER = {\n",
        "    1: 60000,\n",
        "    2: None,   # keep all\n",
        "    3: 60000,\n",
        "    4: 60000,\n",
        "    5: 70000,\n",
        "}\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "# ---------------------------------------- #\n",
        "\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "def downsample_tier(tier):\n",
        "    input_file = os.path.join(INPUT_DIR, f\"CLEVR_train_questions_L{tier}.json\")\n",
        "    output_file = os.path.join(OUTPUT_DIR, f\"CLEVR_train_questions_L{tier}.json\")\n",
        "\n",
        "    with open(input_file, \"r\") as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    questions = data[\"questions\"]\n",
        "\n",
        "    # ---- Tier 2: keep all ----\n",
        "    if tier == 2:\n",
        "        out_data = {\"info\": data.get(\"info\", {}), \"questions\": questions}\n",
        "        with open(output_file, \"w\") as f:\n",
        "            json.dump(out_data, f)\n",
        "        print(f\"âœ… Tier L2: kept ALL {len(questions)}\")\n",
        "        return\n",
        "\n",
        "    # ---- Group by image ----\n",
        "    image_map = defaultdict(list)\n",
        "    for q in questions:\n",
        "        image_map[q[\"image_index\"]].append(q)\n",
        "\n",
        "    image_ids = list(image_map.keys())\n",
        "    random.shuffle(image_ids)\n",
        "\n",
        "    for img_id in image_ids:\n",
        "        random.shuffle(image_map[img_id])\n",
        "\n",
        "    target = TARGET_PER_TIER[tier]\n",
        "    max_per_image = MAX_Q_PER_IMAGE[tier]\n",
        "\n",
        "    collected = []\n",
        "    used = defaultdict(int)\n",
        "\n",
        "    # ---- Round-robin passes ----\n",
        "    for pass_idx in range(max_per_image):\n",
        "        for img_id in image_ids:\n",
        "            if used[img_id] <= pass_idx and pass_idx < len(image_map[img_id]):\n",
        "                collected.append(image_map[img_id][pass_idx])\n",
        "                used[img_id] += 1\n",
        "\n",
        "                if target and len(collected) >= target:\n",
        "                    collected = collected[:target]\n",
        "                    break\n",
        "        if target and len(collected) >= target:\n",
        "            break\n",
        "\n",
        "    random.shuffle(collected)\n",
        "\n",
        "    out_data = {\"info\": data.get(\"info\", {}), \"questions\": collected}\n",
        "    with open(output_file, \"w\") as f:\n",
        "        json.dump(out_data, f)\n",
        "\n",
        "    avg = len(collected) / len(image_ids)\n",
        "    print(\n",
        "        f\"âœ… Tier L{tier}: kept={len(collected)}, \"\n",
        "        f\"avgâ‰ˆ{avg:.2f}, maxâ‰¤{max_per_image}\"\n",
        "    )\n",
        "\n",
        "\n",
        "# -------- RUN FOR ALL TIERS -------- #\n",
        "for tier in [1, 2, 3, 4, 5]:\n",
        "    downsample_tier(tier)\n",
        "\n",
        "print(\"\\nðŸŽ¯ All tiers downsampled with AVG-based logic.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "naTVVQMC3NDZ",
        "outputId": "d52b41ad-6faa-4a78-dd09-8271321f6918"
      },
      "id": "naTVVQMC3NDZ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "âœ… Tier L1: kept=60000, avgâ‰ˆ0.88, maxâ‰¤3\n",
            "âœ… Tier L2: kept ALL 31437\n",
            "âœ… Tier L3: kept=60000, avgâ‰ˆ0.95, maxâ‰¤2\n",
            "âœ… Tier L4: kept=60000, avgâ‰ˆ0.92, maxâ‰¤2\n",
            "âœ… Tier L5: kept=70000, avgâ‰ˆ1.02, maxâ‰¤3\n",
            "\n",
            "ðŸŽ¯ All tiers downsampled with AVG-based logic.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**VALIDATION DOWNSAMPLE**"
      ],
      "metadata": {
        "id": "8fEz7PjBly76"
      },
      "id": "8fEz7PjBly76"
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import random\n",
        "import os\n",
        "from collections import defaultdict\n",
        "from google.colab import drive\n",
        "\n",
        "# -------- MOUNT GOOGLE DRIVE -------- #\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ---------------- CONFIG ---------------- #\n",
        "INPUT_DIR = \"/content/drive/MyDrive/Colab Notebooks/FYP/dataset/clevr_kaggle/CLEVR_v1.0/questions\"\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/Colab Notebooks/FYP/CLEVR/downsampled_val\"\n",
        "\n",
        "MAX_Q_PER_IMAGE = {\n",
        "    1: 2,\n",
        "    2: 1,  # ignored (keep all)\n",
        "    3: 2,\n",
        "    4: 2,\n",
        "    5: 3,\n",
        "}\n",
        "\n",
        "TARGET_PER_TIER = {\n",
        "    1: 8000,\n",
        "    2: None,   # keep all\n",
        "    3: 8000,\n",
        "    4: 8000,\n",
        "    5: 10000,\n",
        "}\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "# ---------------------------------------- #\n",
        "\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "def downsample_val_tier(tier):\n",
        "    input_file = os.path.join(INPUT_DIR, f\"CLEVR_val_questions_L{tier}.json\")\n",
        "    output_file = os.path.join(OUTPUT_DIR, f\"CLEVR_val_questions_L{tier}.json\")\n",
        "\n",
        "    with open(input_file, \"r\") as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    questions = data[\"questions\"]\n",
        "\n",
        "    # ---------- TIER 2: KEEP ALL ----------\n",
        "    if tier == 2:\n",
        "        out_data = {\n",
        "            \"info\": data.get(\"info\", {}),\n",
        "            \"questions\": questions\n",
        "        }\n",
        "        with open(output_file, \"w\") as f:\n",
        "            json.dump(out_data, f)\n",
        "\n",
        "        print(f\"âœ… VAL L2: kept ALL {len(questions)} questions\")\n",
        "        return\n",
        "\n",
        "    # ---------- OTHER TIERS ----------\n",
        "    image_map = defaultdict(list)\n",
        "    for q in questions:\n",
        "        image_map[q[\"image_index\"]].append(q)\n",
        "\n",
        "    image_ids = list(image_map.keys())\n",
        "    random.shuffle(image_ids)\n",
        "\n",
        "    collected = []\n",
        "    target = TARGET_PER_TIER[tier]\n",
        "    cap = MAX_Q_PER_IMAGE[tier]\n",
        "\n",
        "    for img_id in image_ids:\n",
        "        qs = image_map[img_id]\n",
        "        random.shuffle(qs)\n",
        "\n",
        "        collected.extend(qs[:cap])\n",
        "\n",
        "        if len(collected) >= target:\n",
        "            collected = collected[:target]\n",
        "            break\n",
        "\n",
        "    random.shuffle(collected)\n",
        "\n",
        "    out_data = {\n",
        "        \"info\": data.get(\"info\", {}),\n",
        "        \"questions\": collected\n",
        "    }\n",
        "\n",
        "    with open(output_file, \"w\") as f:\n",
        "        json.dump(out_data, f)\n",
        "\n",
        "    print(\n",
        "        f\"âœ… VAL L{tier}: kept={len(collected)} \"\n",
        "        f\"(cap={cap}) â†’ {output_file}\"\n",
        "    )\n",
        "\n",
        "\n",
        "# -------- RUN FOR ALL TIERS -------- #\n",
        "for tier in [1, 2, 3, 4, 5]:\n",
        "    downsample_val_tier(tier)\n",
        "\n",
        "print(\"\\nðŸŽ¯ Validation tiers downsampled successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2FDsJkyl2H5",
        "outputId": "f79e9b61-9749-4c0d-d9f5-a1dcb4332006"
      },
      "id": "h2FDsJkyl2H5",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "âœ… VAL L1: kept=8000 (cap=2) â†’ /content/drive/MyDrive/Colab Notebooks/FYP/CLEVR/downsampled_val/CLEVR_val_questions_L1.json\n",
            "âœ… VAL L2: kept ALL 6780 questions\n",
            "âœ… VAL L3: kept=8000 (cap=2) â†’ /content/drive/MyDrive/Colab Notebooks/FYP/CLEVR/downsampled_val/CLEVR_val_questions_L3.json\n",
            "âœ… VAL L4: kept=8000 (cap=2) â†’ /content/drive/MyDrive/Colab Notebooks/FYP/CLEVR/downsampled_val/CLEVR_val_questions_L4.json\n",
            "âœ… VAL L5: kept=10000 (cap=3) â†’ /content/drive/MyDrive/Colab Notebooks/FYP/CLEVR/downsampled_val/CLEVR_val_questions_L5.json\n",
            "\n",
            "ðŸŽ¯ Validation tiers downsampled successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "from collections import Counter\n",
        "\n",
        "# ðŸ”§ UPDATED PATH FOR COLAB\n",
        "BASE_DIR = \"/content/drive/MyDrive/Colab Notebooks/FYP/CLEVR/downsampled_val\"\n",
        "\n",
        "def analyze_tier(json_path):\n",
        "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    # CLEVR format\n",
        "    questions = data.get(\"questions\", [])\n",
        "    total_q = len(questions)\n",
        "\n",
        "    image_counter = Counter(\n",
        "        q[\"image_filename\"] for q in questions\n",
        "    )\n",
        "\n",
        "    num_images = len(image_counter)\n",
        "    avg_q_per_img = total_q / num_images if num_images else 0\n",
        "    max_q_per_img = max(image_counter.values()) if num_images else 0\n",
        "\n",
        "    return total_q, num_images, avg_q_per_img, max_q_per_img\n",
        "\n",
        "\n",
        "print(\"\\nðŸ“Š CLEVR TRAIN BALANCED DATASET STATS\\n\")\n",
        "\n",
        "# Optional: sanity check\n",
        "print(\"Files found:\", os.listdir(BASE_DIR), \"\\n\")\n",
        "\n",
        "for file in sorted(os.listdir(BASE_DIR)):\n",
        "    if not file.lower().endswith(\".json\"):\n",
        "        continue\n",
        "\n",
        "    tier = None\n",
        "    for t in [\"L1\", \"L2\", \"L3\", \"L4\", \"L5\"]:\n",
        "        if t in file:\n",
        "            tier = t\n",
        "            break\n",
        "\n",
        "    if tier is None:\n",
        "        continue\n",
        "\n",
        "    path = os.path.join(BASE_DIR, file)\n",
        "    total_q, num_images, avg_q, max_q = analyze_tier(path)\n",
        "\n",
        "    print(f\"=== {file} ===\")\n",
        "    print(f\"Tier                  : {tier}\")\n",
        "    print(f\"Total questions       : {total_q}\")\n",
        "    print(f\"Unique images         : {num_images}\")\n",
        "    print(f\"Avg questions / image : {avg_q:.2f}\")\n",
        "    print(f\"Max questions / image : {max_q}\")\n",
        "    print()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtPYJLCal5bN",
        "outputId": "85680ff9-a20f-4cb5-a0c0-d34211244053"
      },
      "id": "xtPYJLCal5bN",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Š CLEVR TRAIN BALANCED DATASET STATS\n",
            "\n",
            "Files found: ['CLEVR_val_questions_L1.json', 'CLEVR_val_questions_L2.json', 'CLEVR_val_questions_L3.json', 'CLEVR_val_questions_L4.json', 'CLEVR_val_questions_L5.json'] \n",
            "\n",
            "=== CLEVR_val_questions_L1.json ===\n",
            "Tier                  : L1\n",
            "Total questions       : 8000\n",
            "Unique images         : 4268\n",
            "Avg questions / image : 1.87\n",
            "Max questions / image : 2\n",
            "\n",
            "=== CLEVR_val_questions_L2.json ===\n",
            "Tier                  : L2\n",
            "Total questions       : 6780\n",
            "Unique images         : 5882\n",
            "Avg questions / image : 1.15\n",
            "Max questions / image : 3\n",
            "\n",
            "=== CLEVR_val_questions_L3.json ===\n",
            "Tier                  : L3\n",
            "Total questions       : 8000\n",
            "Unique images         : 4893\n",
            "Avg questions / image : 1.63\n",
            "Max questions / image : 2\n",
            "\n",
            "=== CLEVR_val_questions_L4.json ===\n",
            "Tier                  : L4\n",
            "Total questions       : 8000\n",
            "Unique images         : 4590\n",
            "Avg questions / image : 1.74\n",
            "Max questions / image : 2\n",
            "\n",
            "=== CLEVR_val_questions_L5.json ===\n",
            "Tier                  : L5\n",
            "Total questions       : 10000\n",
            "Unique images         : 4047\n",
            "Avg questions / image : 2.47\n",
            "Max questions / image : 3\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Xq8GYZwPmOX6"
      },
      "id": "Xq8GYZwPmOX6",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (seli-fyp)",
      "language": "python",
      "name": "seli-fyp"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}