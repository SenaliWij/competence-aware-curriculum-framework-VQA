{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAFMRjZKfGoV",
        "outputId": "c4880d5e-849e-4b5e-b301-1afdab5c3b2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Checking for file at: /content/drive/MyDrive/FYP/FYP impl/CLEVR_train_questions.json\n",
            "✅ File found! Starting processing...\n",
            "Loading JSON data... (This may take 1-2 minutes)\n",
            "Processing 699989 questions...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function ZipFile.__del__ at 0x7cc5137b0c20>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.12/zipfile/__init__.py\", line 1966, in __del__\n",
            "    self.close()\n",
            "  File \"/usr/lib/python3.12/zipfile/__init__.py\", line 1983, in close\n",
            "    self.fp.seek(self.start_dir)\n",
            "ValueError: seek of closed file\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving categorized data to: /content/drive/MyDrive/FYP/FYP impl/CLEVR_Categorized.xlsx\n",
            "✅ Categorized Excel saved successfully.\n",
            "✅ No unmapped operations found.\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "# 1. Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "def process_clevr_from_specific_folder():\n",
        "    # --- CONFIGURATION ---\n",
        "    # We point directly to your specific folder here\n",
        "    folder_path = '/content/drive/MyDrive/FYP/FYP impl'\n",
        "    filename = 'CLEVR_train_questions.json'\n",
        "\n",
        "    input_path = os.path.join(folder_path, filename)\n",
        "    output_mapped = os.path.join(folder_path, \"CLEVR_Categorized.xlsx\")\n",
        "    output_unmapped = os.path.join(folder_path, \"CLEVR_Unmapped.xlsx\")\n",
        "    # ---------------------\n",
        "\n",
        "    # 2. Verify the file exists before starting\n",
        "    print(f\"Checking for file at: {input_path}\")\n",
        "    if not os.path.exists(input_path):\n",
        "        print(f\"❌ Error: File not found at {input_path}\")\n",
        "        print(\"Please check if the folder name 'FYP impl' has a space and matches exactly.\")\n",
        "        return\n",
        "\n",
        "    print(f\"✅ File found! Starting processing...\")\n",
        "\n",
        "    # 3. Define Task Mapping\n",
        "    task_mapping = {\n",
        "        \"count\": \"Counting\", \"exist\": \"Existence\",\n",
        "        \"equal_integer\": \"Compare Integer\", \"less_than\": \"Compare Integer\", \"greater_than\": \"Compare Integer\",\n",
        "        \"query_color\": \"Query Attribute\", \"query_size\": \"Query Attribute\",\n",
        "        \"query_material\": \"Query Attribute\", \"query_shape\": \"Query Attribute\",\n",
        "        \"equal_color\": \"Compare Attribute\", \"equal_size\": \"Compare Attribute\",\n",
        "        \"equal_material\": \"Compare Attribute\", \"equal_shape\": \"Compare Attribute\"\n",
        "    }\n",
        "\n",
        "    print(\"Loading JSON data... (This may take 1-2 minutes)\")\n",
        "    with open(input_path, 'r') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    questions = data.get('questions', [])\n",
        "    categorized_records = {cat: [] for cat in set(task_mapping.values())}\n",
        "    unmapped_records = []\n",
        "\n",
        "    print(f\"Processing {len(questions)} questions...\")\n",
        "    for q in questions:\n",
        "        full_program = q.get('program', [])\n",
        "        if not full_program: continue\n",
        "\n",
        "        last_op = full_program[-1].get('function', 'unknown')\n",
        "\n",
        "        record = {\n",
        "            \"Question Index\": q.get('question_index'),\n",
        "            \"Question\": q.get('question'),\n",
        "            \"Answer\": q.get('answer'),\n",
        "            \"Last Operation\": last_op,\n",
        "            \"Full Program\": \" -> \".join([node['function'] for node in full_program]),\n",
        "            \"Image\": q.get('image_filename')\n",
        "        }\n",
        "\n",
        "        category = task_mapping.get(last_op)\n",
        "        if category:\n",
        "            categorized_records[category].append(record)\n",
        "        else:\n",
        "            unmapped_records.append(record)\n",
        "\n",
        "    # 4. Save to Excel\n",
        "    print(f\"Saving categorized data to: {output_mapped}\")\n",
        "    try:\n",
        "        with pd.ExcelWriter(output_mapped, engine='openpyxl') as writer:\n",
        "            data_written = False\n",
        "            for category, items in categorized_records.items():\n",
        "                if items:\n",
        "                    df = pd.DataFrame(items)\n",
        "                    df.to_excel(writer, sheet_name=category[:31], index=False)\n",
        "                    data_written = True\n",
        "\n",
        "            if not data_written:\n",
        "                pd.DataFrame([\"No Data\"]).to_excel(writer, sheet_name=\"Empty\")\n",
        "\n",
        "        print(\"✅ Categorized Excel saved successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error saving categorized Excel: {e}\")\n",
        "\n",
        "    # 5. Save Unmapped Data (if any)\n",
        "    if unmapped_records:\n",
        "        print(f\"Saving unmapped data to: {output_unmapped}\")\n",
        "        pd.DataFrame(unmapped_records).to_excel(output_unmapped, index=False)\n",
        "        print(f\"⚠️ Found {len(unmapped_records)} unmapped items.\")\n",
        "    else:\n",
        "        print(\"✅ No unmapped operations found.\")\n",
        "\n",
        "# Run the function\n",
        "process_clevr_from_specific_folder()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **CURRICULLUM LEARNING FRAMEWORK  TO IMPROVE COMPOSITIONAL REASONING IN VQA MODELS**"
      ],
      "metadata": {
        "id": "0-t7sOjQ_OrD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **CLEVR DATASET SPLIT INTO REASONING TASK BASED SUBSETS**\n",
        "\n",
        "*   LEVEL1 Attribute & existence, no relate\n",
        "*   LEVEL2 Counting / compare integer, no relate\n",
        "*   LEVEL3 Attribute & existence with relate\n",
        "*   LEVEL4 Count/ Compare (integer or attribute) with strong composition\n",
        "\n",
        "\n",
        "     \n",
        "    \n",
        "    \n"
      ],
      "metadata": {
        "id": "GEF0iSEjZ_69"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "_9nd7wUQgQT6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6989c70-7092-44bf-eb71-3e805c085c91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define function groups + level assignment (L1–L4)"
      ],
      "metadata": {
        "id": "4aAnH0B3Dcvb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "from collections import defaultdict\n",
        "from typing import List, Dict, Any, Optional\n",
        "\n",
        "FOLDER_PATH = '/content/drive/MyDrive/FYP/FYP impl/CLEVR_v1.0/questions'\n",
        "TRAIN_FILENAME = 'CLEVR_train_questions.json'\n",
        "\n",
        "TRAIN_PATH = os.path.join(FOLDER_PATH, TRAIN_FILENAME)\n",
        "\n",
        "print(\"Using CLEVR train file at:\", TRAIN_PATH)\n",
        "assert os.path.exists(TRAIN_PATH), \"Train JSON not found. Check path/name!\"\n",
        "\n",
        "ATTR_QUERY_FNS = {\"query_color\", \"query_shape\", \"query_size\", \"query_material\"}\n",
        "EXIST_FNS = {\"exist\"}\n",
        "COUNT_FNS = {\"count\"}\n",
        "NUM_COMPARE_FNS = {\"equal_integer\", \"greater_than\", \"less_than\"}\n",
        "ATTR_COMPARE_FNS = {\"equal_color\", \"equal_shape\", \"equal_size\", \"equal_material\"}\n",
        "\n",
        "def has_relate(program: List[Dict[str, Any]]) -> bool:\n",
        "    return any(step.get(\"function\") == \"relate\" for step in program)\n",
        "\n",
        "def program_length(program: List[Dict[str, Any]]) -> int:\n",
        "    return len(program)\n",
        "\n",
        "def assign_level(program: List[Dict[str, Any]]) -> Optional[str]:\n",
        "    \"\"\"\n",
        "    Map a CLEVR functional program to curriculum levels L1–L5:\n",
        "\n",
        "    L1: Attribute & existence, no relate\n",
        "    L2: Compare attribute (multi-set), no relate\n",
        "    L3: Counting / integer compare, no relate\n",
        "    L4: Attribute & existence with relate\n",
        "    L5: Count / Compare (integer or attribute) with relate (strong composition)\n",
        "    \"\"\"\n",
        "    if not program:\n",
        "        return None\n",
        "\n",
        "    last_fn = program[-1].get(\"function\", None)\n",
        "    relate = has_relate(program)\n",
        "\n",
        "    # ----- L1: attribute & existence, no relate -----\n",
        "    if (not relate) and (last_fn in ATTR_QUERY_FNS or last_fn in EXIST_FNS):\n",
        "        return \"L1\"\n",
        "\n",
        "    # ----- L2: Compare Attribute (multi-set), no relate -----\n",
        "    if (not relate) and (last_fn in ATTR_COMPARE_FNS):\n",
        "        return \"L2\"\n",
        "\n",
        "    # ----- L3: counting / integer compare, no relate -----\n",
        "    if (not relate) and (last_fn in COUNT_FNS or last_fn in NUM_COMPARE_FNS):\n",
        "        return \"L3\"\n",
        "\n",
        "    # ----- L4: attribute & existence with relate -----\n",
        "    if relate and (last_fn in ATTR_QUERY_FNS or last_fn in EXIST_FNS):\n",
        "        return \"L4\"\n",
        "\n",
        "    # ----- L5: count / compare (integer or attribute) with relate -----\n",
        "    # strong composition: relate + any count/compare op (num or attr)\n",
        "    if relate and (\n",
        "        last_fn in COUNT_FNS\n",
        "        or last_fn in NUM_COMPARE_FNS\n",
        "        or last_fn in ATTR_COMPARE_FNS\n",
        "        or any(\n",
        "            step.get(\"function\") in COUNT_FNS.union(NUM_COMPARE_FNS).union(ATTR_COMPARE_FNS)\n",
        "            for step in program\n",
        "        )\n",
        "    ):\n",
        "        return \"L5\"\n",
        "\n",
        "    # Anything that doesn't fit any of the above will be counted as \"unassigned\"\n",
        "    return None\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FcqOc85yV9V",
        "outputId": "fdfcc40d-50c2-4e80-db84-80d560c4408f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using CLEVR train file at: /content/drive/MyDrive/FYP/FYP impl/CLEVR_v1.0/questions/CLEVR_train_questions.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split into L1–L4 and save into same folder"
      ],
      "metadata": {
        "id": "SkrLFPZ01eZQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_train_questions(path: str) -> Dict[str, Any]:\n",
        "    with open(path, \"r\") as f:\n",
        "        data = json.load(f)\n",
        "    assert \"questions\" in data, \"Expected key 'questions' in CLEVR JSON\"\n",
        "    return data\n",
        "\n",
        "def save_questions(level: str, questions: List[Dict[str, Any]]) -> str:\n",
        "    out_name = f\"CLEVR_train_questions_{level}.json\"\n",
        "    out_path = os.path.join(FOLDER_PATH, out_name)\n",
        "    out_data = {\"questions\": questions}\n",
        "    with open(out_path, \"w\") as f:\n",
        "        json.dump(out_data, f)\n",
        "    print(f\"Saved {len(questions):7d} questions to {out_path}\")\n",
        "    return out_path\n",
        "\n",
        "def build_train_curriculum_splits():\n",
        "    data = load_train_questions(TRAIN_PATH)\n",
        "    all_questions = data[\"questions\"]\n",
        "    total_questions = len(all_questions)\n",
        "\n",
        "    # Buckets for L1–L5\n",
        "    buckets = defaultdict(list)\n",
        "\n",
        "    # Track questions that did not match any level\n",
        "    unassigned = []\n",
        "\n",
        "    for q in all_questions:\n",
        "        program = q.get(\"program\", [])\n",
        "        level = assign_level(program)\n",
        "        if level is None:\n",
        "            unassigned.append(q)\n",
        "            continue\n",
        "        buckets[level].append(q)\n",
        "\n",
        "    # Save per-level files\n",
        "    stats = {}\n",
        "    for lvl in sorted(buckets.keys()):\n",
        "        stats[lvl] = len(buckets[lvl])\n",
        "        save_questions(lvl, buckets[lvl])\n",
        "\n",
        "    # Summary\n",
        "    print(\"\\nSummary (train questions per level):\")\n",
        "    assigned_total = 0\n",
        "    for lvl in sorted(stats.keys()):\n",
        "        print(f\"  {lvl}: {stats[lvl]}\")\n",
        "        assigned_total += stats[lvl]\n",
        "\n",
        "    unassigned_count = len(unassigned)\n",
        "    print(f\"\\nTotal questions in original file: {total_questions}\")\n",
        "    print(f\"Total assigned to L1–L5:         {assigned_total}\")\n",
        "    print(f\"Total unassigned (no level):     {unassigned_count}\")\n",
        "\n",
        "build_train_curriculum_splits()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WycFjemOyY-m",
        "outputId": "18da50fa-69b7-4f3e-8911-e11bba47dc19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved  196519 questions to /content/drive/MyDrive/FYP/FYP impl/CLEVR_v1.0/questions/CLEVR_train_questions_L1.json\n",
            "Saved   31437 questions to /content/drive/MyDrive/FYP/FYP impl/CLEVR_v1.0/questions/CLEVR_train_questions_L2.json\n",
            "Saved  126260 questions to /content/drive/MyDrive/FYP/FYP impl/CLEVR_v1.0/questions/CLEVR_train_questions_L3.json\n",
            "Saved  149316 questions to /content/drive/MyDrive/FYP/FYP impl/CLEVR_v1.0/questions/CLEVR_train_questions_L4.json\n",
            "Saved  196457 questions to /content/drive/MyDrive/FYP/FYP impl/CLEVR_v1.0/questions/CLEVR_train_questions_L5.json\n",
            "\n",
            "Summary (train questions per level):\n",
            "  L1: 196519\n",
            "  L2: 31437\n",
            "  L3: 126260\n",
            "  L4: 149316\n",
            "  L5: 196457\n",
            "\n",
            "Total questions in original file: 699989\n",
            "Total assigned to L1–L5:         699989\n",
            "Total unassigned (no level):     0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sInSOT-VzXRP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}