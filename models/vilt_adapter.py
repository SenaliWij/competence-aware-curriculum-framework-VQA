# -*- coding: utf-8 -*-
"""ViLT_adapter.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bx9PAv6wVrnmKnXRzoT1RDUTr-dRF3R8
"""

from google.colab import drive
drive.mount('/content/drive')

import torch
import torch.nn as nn
from transformers import ViltForQuestionAnswering
from base_model import ModelAdapter
from typing import Dict, Any

class ViLTAdapter(ModelAdapter):
    def __init__(self, model_name: str = "dandelin/vilt-b32-mlm-itm", num_labels: int = 28, learning_rate: float = 5e-5, device: str = 'cuda'):
        self.device = torch.device(device if torch.cuda.is_available() else 'cpu')

        # Initialize model
        # We assume ViltForQuestionAnswering is used.
        # For custom num_labels, we might need to ignore mismatched sizes or instantiate fresh.
        # Here we assume standard usage:
        self.model = ViltForQuestionAnswering.from_pretrained(
            model_name,
            num_labels=num_labels,
            ignore_mismatched_sizes=True
        )
        self.model.to(self.device)

        self.optimizer = torch.optim.AdamW(self.model.parameters(), lr=learning_rate)

    def train_step(self, batch: Dict[str, Any]) -> Dict[str, float]:
        self.model.train()

        inputs = {k: v for k, v in batch.items() if k in ['input_ids', 'attention_mask', 'token_type_ids', 'pixel_values', 'pixel_mask', 'labels']}
        # move to device first (so multi_hot is also on correct device)
        inputs = {k: v.to(self.device) for k, v in inputs.items()}

        # convert labels -> multi-hot
        labels = inputs["labels"]  # [B]
        num_labels = self.model.config.num_labels

        multi_hot = torch.zeros(labels.size(0), num_labels, device=labels.device)
        multi_hot.scatter_(1, labels.long().unsqueeze(1), 1.0)
        inputs["labels"] = multi_hot

        self.optimizer.zero_grad()
        outputs = self.model(**inputs)
        loss = outputs.loss
        loss.backward()
        self.optimizer.step()

        return {'loss': loss.item()}

    def validation_step(self, batch: Dict[str, Any]) -> Dict[str, Any]:
        self.model.eval()
        with torch.no_grad():
              inputs = {k: v for k, v in batch.items() if k in ['input_ids', 'attention_mask', 'token_type_ids', 'pixel_values', 'pixel_mask', 'labels']}
              # move to device first (so multi_hot is also on correct device)
              inputs = {k: v.to(self.device) for k, v in inputs.items()}

              # convert labels -> multi-hot
              labels = inputs["labels"]  # [B]
              num_labels = self.model.config.num_labels

              multi_hot = torch.zeros(labels.size(0), num_labels, device=labels.device)
              multi_hot.scatter_(1, labels.long().unsqueeze(1), 1.0)
              inputs["labels"] = multi_hot

              outputs = self.model(**inputs)

        return {
            'logits': outputs.logits.cpu(),
            'labels': inputs.get('labels').cpu() if 'labels' in inputs else None,
            'loss': outputs.loss.item() if outputs.loss is not None else 0.0
        }

    def save(self, path: str):
        torch.save(self.model.state_dict(), path)

    def load(self, path: str):
        self.model.load_state_dict(torch.load(path, map_location=self.device))

    def get_state_dict(self):
        return self.model.state_dict()

    def get_optimizer_state_dict(self):
        return self.optimizer.state_dict()

    def load_optimizer_state(self, state_dict):
        self.optimizer.load_state_dict(state_dict)

